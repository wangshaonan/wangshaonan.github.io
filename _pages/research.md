---
title: "Research"
permalink: /research/
author_profile: true
---

<style>
.project-box {
    border: 2px solid #ddd;
    border-radius: 10px;
    padding: 20px;
    margin: 20px 0;
    display: flex;
    align-items: center;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
}

.project-box img {
    max-width: 300px; /* Adjust as needed */
    max-height: 300px; /* Adjust as needed */
    border-radius: 10px;
    margin-right: 20px;
}

.project-box .content {
    flex-grow: 1;
}

.project-box h3 {
    margin: 0 0 10px 0;
}

.project-box p {
    margin: 0;
}
</style>

<div class="project-box">
    <img src="https://raw.githubusercontent.com/wangshaonan/wangshaonan.github.io/master/research/compfunc.png" alt="Project Image">
    <div class="content">
        <h3>Phrasal composition mechanism of human</h3>
        <p> Understanding the computational operations involved in conceptual composition is fundamental for theories of language. However, the existing literature on this topic remains fragmented, comprising disconnected theories from various fields. For instance, while formal semantic theories in Linguistics rely on type-driven interpretation without explicitly representing the conceptual content of lexical items, neurolinguistic research suggests that the brain is sensitive to conceptual factors during word composition. What is the relationship between these two types of theories? Do they describe two distinct aspects of composition, operating independently, or do they connect in some way during interpretation by our brain? To probe this, we explored how the mathematical operations explaining the combination of two words into a phrase are affected by the semantic content of items and the formal linguistic relations between the combining items. </p>
    </div>
</div>

<div class="project-box">
    <img src="https://raw.githubusercontent.com/wangshaonan/wangshaonan.github.io/master/research/comptrans.png" alt="Project Image">
    <div class="content">
        <h3>Phrasal composition in transformer models</h3>
        <p>Transformer models have proven to be an efficient architecture for large language models, enabling them to exhibit human-like behaviors. However, it remains unclear how they combine the properties of individual words. To investigate this, we focus on the simplest compositional unit—two-word phrases—and employ four simple, parameter-free composition operations: addition, multiplication, first word, and second word. This approach serves as the first step toward understanding the composition mechanisms in transformer modules.</p>
    </div>
</div>

<div class="project-box">
    <img src="https://raw.githubusercontent.com/wangshaonan/wangshaonan.github.io/master/research/brainword.png" alt="Project Image">
    <div class="content">
        <h3>Semantic representation of words in our brain</h3>
        <p>Multiple sensory-motor and non-sensory-motor dimensions have been proposed for semantic representation, but it remains unclear how the semantic system is organized along them in the human brain. Using naturalistic fMRI data and large-scale semantic ratings, we investigated the overlaps and dissociations between the neural correlates of six semantic dimensions: vision, motor, socialness, emotion, space, and time. Our findings revealed a more complex semantic atlas than what is predicted by current neurobiological models of semantic representation.</p>
    </div>
</div>
